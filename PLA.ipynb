{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#El algoritmo del perceptrón, y el error en muestra y fuera de muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta práctica tiene como fin poner en relieve las ideas básicas de el aprendizaje, utilizando uno de los métodos de aprendizaje más antiguos y fáciles de implementar.\n",
    "\n",
    "Esta práctica no intenta ser un remplazo del curso, por lo que se asume que los estudiantes conocen el algoritmo de aprendizaje del perceptrón (PLA por sus sigles en inglés), así como las ideas básicas sobre error en muestra y error fuera de muestra. Para esta práctica se puede realizar el problema en cualquier lenguaje de computación que conozca el estudiante. Sin embargo, se recomienda un lenguaje con capacidades de graficación, tal como Matlab, R y Python (con numpy y matplotlib).\n",
    "\n",
    "Recordemos que el error fuera de muestra E_o es el error sobre todo el conjunto de puntos del espacio X. Una vez definido el criterio del error, el objetivo del aprendizaje es encontrar una hipótesis g en el conjunto de todas las hipótesis posibles que se pueden hacer con el método de aprendizaje.\n",
    "\n",
    "Lamentablemente, en todos los casos reales se desconoce E_o y lo más que se puede esperar es aproximarlo a partir del error en muestra E_i, el cual se define como el error medio de un conjunto de datos de aprendizaje disponibles.\n",
    "\n",
    "Para el caso del perceptrón, E_o es la esperanza que un dato se encuentre mal clasificado, y E_i es el porcentaje de datos mal clasificados por el perceptrón. Tambien sabemos, por lo visto en el curso, que si el conjunto de datos que se utiliza en el algoritmo de PLA es linealmente separable, entonces siempre se tiene una hipótesis final g tal que E_i = 0.\n",
    "\n",
    "Entonces, ¿Si E_i = 0, podríamos decir que el PLA aprende perfectamente? Desgraciadamente esto es falso. ¿Y eso porqué? Pues porque lo que nos interesa es E_o = 0 y no E_i = 0. Esta práctica tiene como fin dejar clara la diferencia entre E_i y E_o.\n",
    "\n",
    "Para esto, vamos a hacer un poco de trampa, vamos a suponer que nosotros efectivamente conocemos la función con la que se generaron los datos de aprendizaje, la cual va a ser una función del tipo y = sign(k_0 + k_1 * x_1 + k_2 * x_2). Después vamos a generar datos con esta función, y vamos a estimar g(x) = sign(w_0 + w_1 * x_1 + w_2 * x_2) con el PLA. Así nosotros podemos hacer una estimación suficientemente aproximada de que tan grande es en general la diferencia entre E_i y E_o para diferente número de datos en el conjunto de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Práctica a realizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Desarrolla una función `modelo_aleatorio` en el cual:\n",
    "\n",
    "\ta. Se soliciten 4 numeros aleatorios entre el 0 y el 1, a los que llamaremos x1, y1, x2, y2.\n",
    "\n",
    "\tb. Se obtenga el valor de os pesos de la recta que pasa entre los dos puntos calculados como:\n",
    "\n",
    "        k_2 = 1\n",
    "        k_1 = (y2 - y1) / (x2 - x1)\n",
    "        k_0 = y_1 - k_1 * x_1\n",
    "\n",
    "\n",
    "\tde forma que:\n",
    "\n",
    "        k_0, k_1, k_2 = modelo_aleatorio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelo_aleatorio():\n",
    "\n",
    "    x1 = np.random.uniform(0,1)\n",
    "    y1 = np.random.uniform(0,1)\n",
    "    x2 = np.random.uniform(0,1)\n",
    "    y2 = np.random.uniform(0,1)\n",
    "\n",
    "    k_2 = 1.0 \n",
    "    k_1 = (y2 - y1) / (x2 - x1) \n",
    "    k_0 = y1 - k_1 * x1 \n",
    "\n",
    "    return k_0, k_1, k_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 1: modelo_aleatorio \n",
      "\n",
      "k_0: 9.56564678461\n",
      "k_1: -14.6881902699\n",
      "k_2: 1.0\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 1: modelo_aleatorio \\n\"\n",
    "\n",
    "k_0, k_1, k_2 = modelo_aleatorio()\n",
    "\n",
    "print \"k_0:\", k_0\n",
    "print \"k_1:\", k_1\n",
    "print \"k_2:\", k_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desarrolla una función `genera_datos` tal que reciba un número entero positivo `N` y devuelva una matriz `X` \n",
    "   de `N` renglones y 2 columnas de manera que los valores de la matriz sean datos aleatorios en el intervalo [0, 1].\n",
    "   ```\n",
    "   X = genera_datos(N)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genera_datos(N):\n",
    "\n",
    "    return None if N <= 0 else np.column_stack((np.ones(N), (np.random.uniform(0, 1, size=(N, 2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 2: genera_datos \n",
      "\n",
      "Matriz X: \n",
      "\n",
      "[[ 1.          0.71804745  0.67959322]\n",
      " [ 1.          0.79356873  0.32876212]\n",
      " [ 1.          0.20009616  0.44538314]\n",
      " [ 1.          0.18017485  0.3238359 ]\n",
      " [ 1.          0.14770865  0.43359907]\n",
      " [ 1.          0.11789248  0.116258  ]\n",
      " [ 1.          0.20977513  0.35388107]\n",
      " [ 1.          0.01529173  0.54485276]\n",
      " [ 1.          0.07118083  0.62452072]\n",
      " [ 1.          0.27320267  0.51559774]\n",
      " [ 1.          0.80429774  0.83357618]\n",
      " [ 1.          0.99094769  0.75449559]\n",
      " [ 1.          0.27849695  0.1733744 ]\n",
      " [ 1.          0.82740589  0.72290075]\n",
      " [ 1.          0.55825866  0.72083898]\n",
      " [ 1.          0.43655576  0.78823525]\n",
      " [ 1.          0.70491594  0.97705001]\n",
      " [ 1.          0.55482505  0.35296887]\n",
      " [ 1.          0.22075402  0.47751191]\n",
      " [ 1.          0.06693352  0.69111075]\n",
      " [ 1.          0.71647372  0.65347329]\n",
      " [ 1.          0.52562606  0.34119328]\n",
      " [ 1.          0.02633367  0.13791563]\n",
      " [ 1.          0.07854976  0.7738456 ]\n",
      " [ 1.          0.88256703  0.71674092]]\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 2: genera_datos \\n\"\n",
    "\n",
    "X = genera_datos(25)\n",
    "\n",
    "print \"Matriz X: \\n\"\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desarrolla una función `discriminante_lineal` tal que reciba tres valores `k_0` `k_1` y `k_2` y  una matriz `X` de    2 por `N` y devuelva un vector `Y` de `N` elementos tales que por cada renglon `j` de la matriz X, se devuelva el \n",
    "   `j`-ésimo valor del vector `Y` tal que su valor sea `sign(k_0 + k_1 * x_1 + k_2 * x_2)`.\n",
    "   ```\n",
    "   Y = discriminante_lineal(k_0, k_1, k_2, X) \n",
    "   ``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminante_lineal(k_0, k_1, k_2, X):\n",
    "\n",
    "    Y = []\n",
    "\n",
    "    for i in xrange(X.shape[0]):\n",
    "        x_1 = X[i][1]\n",
    "        x_2 = X[i][2]\n",
    "        Y.append(np.sign(k_0 + k_1 * x_1 + k_2 * x_2))\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 3: discriminante_lineal \n",
      "\n",
      "Y: [-1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0]\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 3: discriminante_lineal \\n\"\n",
    "\n",
    "Y = discriminante_lineal(k_0, k_1, k_2, X)\n",
    "\n",
    "print \"Y:\", Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desarrolla una función `PLA` que implemente el algoritmo de aprendizaje del perceptrón para encontrar \n",
    "   `w_0`, `w_1` y `w_2`.\n",
    "   ```\n",
    "   w_0, w_1, w_2 = PLA(X, Y)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PLA(X, Y):\n",
    "\n",
    "    w = np.ones(X.shape[1])\n",
    "    indice = np.arange(0, X.shape[0])\n",
    "    flag = False\n",
    "    \n",
    "    while flag != True:\n",
    "        \n",
    "        np.random.shuffle(indice)\n",
    "        flag = True\n",
    "\n",
    "        for i in indice:\n",
    "\n",
    "            Y_e = np.sign(np.dot(X[i], w))\n",
    "\n",
    "            if Y[i] != Y_e:\n",
    "                w = w + np.dot(Y[i], X[i])\n",
    "                flag = False\n",
    "                break\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 4: PLA \n",
      "\n",
      "w_0: 2.0\n",
      "w_1: -3.21037891198\n",
      "w_2: 0.448412939885\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 4: PLA \\n\"\n",
    "\n",
    "w_0, w_1, w_2 = PLA(X, Y)\n",
    "\n",
    "print \"w_0:\", w_0\n",
    "print \"w_1:\", w_1\n",
    "print \"w_2:\", w_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desarrolla una función `error_clasificacion` que reciba un vector de valores `Y`y un vector de valores `Y_e` y \n",
    "   calcule el porcentaje de valores diferentes entre ambos vectores\n",
    "   ```\n",
    "   e = error_clasificacion(Y, Y_e)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_clasificacion(Y, Y_e):\n",
    "    \n",
    "    c = 0\n",
    "\n",
    "    for i in xrange(len(Y)):\n",
    "        \n",
    "        if Y[i] != Y_e[i]:\n",
    "            c += 1\n",
    "\n",
    "    return c / float(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 5: error_clasificacion \n",
      "\n",
      "E_i: 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 5: error_clasificacion \\n\"\n",
    "\n",
    "E_i = error_clasificacion(Y, Y)\n",
    "\n",
    "print \"E_i:\", E_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prueba que el conjunto funciona, esto es, para diferentes valores de `N` y repetidos tantas veces \n",
    "   como sea necesario al realizar lo siguiente:\n",
    "   ```\n",
    "   k_0, k_1, k_2 = modelo_aleatorio()\n",
    "   X = genera_datos(N)\n",
    "   Y = discriminante_lineal(k_0, k_1, k_2, X)\n",
    "   w_0, w_1, w_2 = PLA(X, Y)\n",
    "   Y_e = discriminante_lineal(w_0, w_1, w_2, X)\n",
    "   E_i = error_clasificacion(Y, Y_e)\n",
    "   ```\n",
    "   en todos los casos `e` debe de ser 0 o un valor muy cercano (como `1e-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 6: prueba E_i \n",
      "\n",
      "E_i de 1000 : 0.0\n",
      "E_i de 2000 : 0.0\n",
      "E_i de 3000 : 0.0\n",
      "E_i de 4000 : 0.0\n",
      "E_i de 5000 : 0.0\n",
      "E_i de 6000 : 0.0\n",
      "E_i de 7000 : 0.0\n",
      "E_i de 8000 : 0.0\n",
      "E_i de 9000 : 0.0\n",
      "E_i de 10000 : 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 6: prueba E_i \\n\"\n",
    "\n",
    "for N in xrange(1000, 10000 + 1000, 1000):\n",
    "\n",
    "    k_0, k_1, k_2 = modelo_aleatorio()\n",
    "    X = genera_datos(N)\n",
    "    Y = discriminante_lineal(k_0, k_1, k_2, X)\n",
    "    w_0, w_1, w_2 = PLA(X, Y)\n",
    "    Y_e = discriminante_lineal(w_0, w_1, w_2, X)\n",
    "    E_i = error_clasificacion(Y, Y_e)\n",
    "\n",
    "    print \"E_i de\", N, \":\", E_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `E_i` Es en este caso el error en muestra, que es el que se obtiene de verificar el error que el clasificador\n",
    "   (descrito por `w_0`, `w_1` y `w_2`) presenta respecto a los datos reales, pero únicamente de datos de aprendizaje.\n",
    "   \n",
    "   Este error no es exactamente el error fuera de muestra, y para calcular dicho error en el plano [0, 1] x [0, 1]\n",
    "   hay que realizar algunas operaciones de geometría analítica que no siempre son sencillas. Por esta razón vamos a\n",
    "   considerar estimar el E_out, con un conjunto de datos sensiblemente mayor al que utilizamos para el aprendizaje.\n",
    "   por ejemplo:\n",
    "   ```\n",
    "   X_o = genera_datos(10000)\n",
    "   Y_o = discriminante_lineal(k_0, k_1, k_2, X_o)\n",
    "   Y_eo = discriminante_lineal(w_0, w_1, w_2, X_o)\n",
    "   E_o = error_clasificacion(Y_o, Y_eo)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 7: prueba E_o \n",
      "\n",
      "E_o: 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 7: prueba E_o \\n\"\n",
    "\n",
    "X_o = genera_datos(10000)\n",
    "Y_o = discriminante_lineal(k_0, k_1, k_2, X_o)\n",
    "Y_eo = discriminante_lineal(w_0, w_1, w_2, X_o)\n",
    "E_o = error_clasificacion(Y_o, Y_eo)\n",
    "\n",
    "print \"E_o:\", E_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ahora vamos a comparar con un número diferente de datos de aprendizaje, como E_o cambia en terminos generales. \n",
    "   Con el fin de generalizar, haga una función que reciba un valor `N` y devuelva un `E_o_prom` estimado de la \n",
    "   siguiente forma:\n",
    "   ```\n",
    "   Entrada: N\n",
    "   Salida: E_o_prom\n",
    "   \n",
    "   E_lista = arreglo e numeros de 500 espacios\n",
    "   X_o = genera_datos(10000)\n",
    "\n",
    "   para epoch de 1 a 100:\n",
    "      k_0, k_1, k_2 = modelo_aleatorio()\n",
    "      Y_o = discriminante_lineal(k_0, k_1, k_2, X_o)\n",
    "\n",
    "      para iter de 1 a 100:\n",
    "          X = genera_datos(N)\n",
    "          Y = discriminante_lineal(k_0, k_1, k_2, X)\n",
    "          w_0, w_1, w_2 = PLA(X, Y)\n",
    "          Y_eo = discriminante_lineal(w_0, w_1, w_2, X_o)\n",
    "          E_o = error_clasificacion(Y_o, Y_eo)\n",
    "          E_lista[100 * epoch + iter] = E_o\n",
    "      fin para\n",
    "\n",
    "   fin para\n",
    "\n",
    "   devuelve el valor promedio de los valores de E_lista\n",
    "   ```\n",
    "   Como puede verse en el pseudocódigo, la idea es poder estimar en forma general el error promedio entre el \n",
    "   E_i y el E_o que tendríamos si tuvieramos solo `N` datos de aprendizaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_o_prom(N):\n",
    "\n",
    "    E_lista = np.zeros(500)\n",
    "    X_o = genera_datos(10000)\n",
    "\n",
    "    for epoch in xrange(1, 100):\n",
    "        k_0, k_1, k_2 = modelo_aleatorio()\n",
    "        Y_o = discriminante_lineal(k_0, k_1, k_2, X_o)\n",
    "\n",
    "        for iter in xrange(1, 100):\n",
    "            X = genera_datos(N)\n",
    "            Y = discriminante_lineal(k_0, k_1, k_2, X)\n",
    "            w_0, w_1, w_2 = PLA(X, Y)\n",
    "            Y_eo = discriminante_lineal(w_0, w_1, w_2, X_o)\n",
    "            E_o = error_clasificacion(Y_o, Y_eo)\n",
    "            indice = 100 * epoch + iter\n",
    "        \n",
    "            if len(E_lista) <= indice:\n",
    "                temp = np.zeros(indice + 1)\n",
    "                for i in xrange(0, len(E_lista)):\n",
    "                    temp[i] = E_lista[i]\n",
    "                temp[indice] = E_o\n",
    "                E_lista = temp[:]\n",
    "            else:\n",
    "                E_lista[indice] = E_o\n",
    "\n",
    "    return sum(E_lista) / len(E_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 8: pseudocodigo E_o_prom \n",
      "\n",
      "E_o_prom 0.03425929\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 8: pseudocodigo E_o_prom \\n\"\n",
    "\n",
    "E_o_prom = E_o_prom(10)\n",
    "\n",
    "print \"E_o_prom\", E_o_prom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explica en forma gráfica que es lo que se está haciendo y que es el valor que estamos midiendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 9: grafica \n",
      "\n",
      "N: 10    E_o: 0.04893768\n",
      "N: 20    E_o: 0.02371382\n",
      "N: 30    E_o: 0.01695317\n",
      "N: 40    E_o: 0.01257113\n",
      "N: 50    E_o: 0.00835986\n",
      "N: 60    E_o: 0.00757003\n",
      "N: 70    E_o: 0.0079465\n",
      "N: 80    E_o: 0.00625278\n",
      "N: 90    E_o: 0.00468784\n",
      "N: 100    E_o: 0.00548626\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEACAYAAABGYoqtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3d6a91390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Funcion 9: grafica \\n\"\n",
    "\n",
    "E_o = []\n",
    "N = np.arange(10, 100+10, 10)\n",
    "\n",
    "for i in N:\n",
    "    \n",
    "    e_o = E_o_prom(i)\n",
    "    E_o.append(e_o)\n",
    "\n",
    "for i in xrange(len(N)):\n",
    "    \n",
    "    print \"N: \" + str(N[i]) + \"    \" + \"E_o: \" + str(E_o[i])\n",
    "\n",
    "\n",
    "x = [x for x in N]\n",
    "y = [y for y in E_o]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Realiza una tabla con los valores de `E_o_prom` para `N` que tome los valores de 10, 20, 50, 100, 500 \n",
    "    respectivamente. Escribe claramente tus conclusiones de este trabajo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion 10: tabla de E_o_prom \n",
      "\n",
      "N: 10    E_o: 0.00457307692308\n",
      "N: 20    E_o: 0.00309945054945\n",
      "N: 50    E_o: 0.00051021978022\n",
      "N: 100    E_o: 0.000849450549451\n",
      "N: 500    E_o: 9.96703296703e-05\n"
     ]
    }
   ],
   "source": [
    "print \"Funcion 10: tabla de E_o_prom \\n\"\n",
    "\n",
    "e1 = E_o_prom(10)\n",
    "e2 = E_o_prom(20)\n",
    "e3 = E_o_prom(50)\n",
    "e4 = E_o_prom(100)\n",
    "e5 = E_o_prom(500)\n",
    "\n",
    "print \"N: \" + str(10) + \"    \" + \"E_o: \" + str(e1) \n",
    "print \"N: \" + str(20) + \"    \" + \"E_o: \" + str(e2) \n",
    "print \"N: \" + str(50) + \"    \" + \"E_o: \" + str(e3) \n",
    "print \"N: \" + str(100) + \"    \" + \"E_o: \" + str(e4) \n",
    "print \"N: \" + str(500) + \"    \" + \"E_o: \" + str(e5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
